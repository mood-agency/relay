/**
 * Test script generation using LLM
 */

import pLimit from 'p-limit';
import type {
  TestPlan,
  TestEntry,
  E2EScenario,
  BuildOptions,
  BatchScriptResult,
  ManifestEntry,
} from '../types.js';
import { LLMClient } from '../llm/client.js';
import { PromptLoader, renderTemplate, cleanJsonResponse, cleanCodeResponse } from './templates.js';
import {
  writeFile,
  writeJson,
  fileExists,
  ensureDir,
  testNameToFilename,
  resolvePath,
} from '../utils/files.js';
import { step, success, error, warn, ProgressCounter } from '../utils/progress.js';
import path from 'path';

/**
 * Callback for when a script is generated
 */
export type ScriptCallback = (testName: string, code: string) => Promise<{ written: boolean }>;

/**
 * Build test scripts from a test plan
 */
export async function buildScripts(
  plan: TestPlan,
  options: BuildOptions,
): Promise<{ scripts: Array<{ name: string; code: string }>; manifest: ManifestEntry[] }> {
  const client = new LLMClient({
    model: options.model,
    provider: options.provider,
    apiBase: options.apiBase,
  });

  const loader = new PromptLoader(options.promptDir);
  const outputDir = resolvePath(options.output);

  // Ensure output directory exists
  await ensureDir(outputDir);

  step('ü§ñ', `Using LLM: ${client.getInfo()}`);

  // Track manifest entries
  const manifest: ManifestEntry[] = [];
  let idCounter = 0;

  // Create callback to write files incrementally
  const writeScript: ScriptCallback = async (testName: string, code: string) => {
    const filename = testNameToFilename(testName);
    const filePath = path.join(outputDir, filename);

    // Add to manifest
    idCounter++;
    manifest.push({
      id: idCounter,
      name: testName,
      file: filename,
    });

    // Check if file exists
    if (!options.overwrite && (await fileExists(filePath))) {
      return { written: false };
    }

    // Write file with header
    const content = `// Test: ${testName}\n// Generated by Rohan\n\n${code}`;
    await writeFile(filePath, content);
    return { written: true };
  };

  let scripts: Array<{ name: string; code: string }>;

  if (plan.e2e) {
    scripts = await buildE2EScripts(plan.scenarios, client, loader, options, writeScript);
  } else {
    const useBatching = options.batchSize > 1;
    if (useBatching) {
      scripts = await buildScriptsBatched(plan.tests, client, loader, options, writeScript);
    } else {
      scripts = await buildScriptsIndividual(plan.tests, client, loader, options, writeScript);
    }
  }

  // Write manifest
  const manifestPath = path.join(outputDir, 'manifest.json');
  await writeJson(manifestPath, manifest);
  step('üìÑ', `Wrote manifest to ${manifestPath} (${manifest.length} entries)`);

  return { scripts, manifest };
}

/**
 * Build scripts individually (one LLM call per test)
 */
async function buildScriptsIndividual(
  tests: TestEntry[],
  client: LLMClient,
  loader: PromptLoader,
  options: BuildOptions,
  onScript: ScriptCallback,
): Promise<Array<{ name: string; code: string }>> {
  const prompts = await loader.loadBuilderPrompts(false, false);
  const limit = pLimit(options.workers);

  const progress = new ProgressCounter(tests.length, 'Building scripts');

  // Rate limiter
  const rpmDelay = options.rpm > 0 ? 60000 / options.rpm : 0;
  let lastRequestTime = 0;

  const tasks = tests.map(test =>
    limit(async () => {
      // Rate limiting
      if (rpmDelay > 0) {
        const now = Date.now();
        const timeSinceLastRequest = now - lastRequestTime;
        if (timeSinceLastRequest < rpmDelay) {
          await new Promise(resolve => setTimeout(resolve, rpmDelay - timeSinceLastRequest));
        }
        lastRequestTime = Date.now();
      }

      const endpointSpec = JSON.stringify(test.endpoint_spec, null, 2);
      const userPrompt = renderTemplate(prompts.user, {
        test_name: test.name,
        endpoint_spec: endpointSpec,
      });

      try {
        const response = await client.generateWithRetry(prompts.system, userPrompt);
        const code = cleanCodeResponse(response);

        const { written } = await onScript(test.name, code);
        if (written) {
          success(`${test.name} (written)`);
        } else {
          step('‚è≠Ô∏è', `${test.name} (skipped)`);
        }

        progress.increment();
        return { name: test.name, code };
      } catch (err) {
        const message = err instanceof Error ? err.message : String(err);
        error(`${test.name} - ${message}`);
        progress.increment();
        return null;
      }
    }),
  );

  const results = await Promise.all(tasks);
  progress.succeed(`Built ${tests.length} scripts`);

  return results.filter((r): r is { name: string; code: string } => r !== null);
}

/**
 * Build scripts in batches (multiple tests per LLM call)
 */
async function buildScriptsBatched(
  tests: TestEntry[],
  client: LLMClient,
  loader: PromptLoader,
  options: BuildOptions,
  onScript: ScriptCallback,
): Promise<Array<{ name: string; code: string }>> {
  const prompts = await loader.loadBuilderPrompts(true, false);
  const limit = pLimit(options.workers);

  // Create batches
  const batches: TestEntry[][] = [];
  for (let i = 0; i < tests.length; i += options.batchSize) {
    batches.push(tests.slice(i, i + options.batchSize));
  }

  step('üì¶', `Batching: ${options.batchSize} tests per request (${batches.length} batches)`);

  const progress = new ProgressCounter(batches.length, 'Building batches');

  // Rate limiter
  const rpmDelay = options.rpm > 0 ? 60000 / options.rpm : 0;
  let lastRequestTime = 0;

  const tasks = batches.map((batch, batchIndex) =>
    limit(async () => {
      // Rate limiting
      if (rpmDelay > 0) {
        const now = Date.now();
        const timeSinceLastRequest = now - lastRequestTime;
        if (timeSinceLastRequest < rpmDelay) {
          await new Promise(resolve => setTimeout(resolve, rpmDelay - timeSinceLastRequest));
        }
        lastRequestTime = Date.now();
      }

      const testsJson = batch.map(test => ({
        test_name: test.name,
        endpoint_spec: test.endpoint_spec,
      }));

      const userPrompt = renderTemplate(prompts.user, {
        tests: JSON.stringify(testsJson, null, 2),
      });

      try {
        const response = await client.generateWithRetry(prompts.system, userPrompt);
        const cleanJson = cleanJsonResponse(response);
        const results: BatchScriptResult = JSON.parse(cleanJson);

        const scripts: Array<{ name: string; code: string }> = [];

        for (const test of batch) {
          const rawCode = results[test.name];
          if (rawCode) {
            const code = cleanCodeResponse(rawCode);
            const { written } = await onScript(test.name, code);
            if (written) {
              success(`${test.name} (written)`);
            } else {
              step('‚è≠Ô∏è', `${test.name} (skipped)`);
            }
            scripts.push({ name: test.name, code });
          } else {
            warn(`${test.name} - Missing from batch response`);
          }
        }

        step('üì¶', `Batch ${batchIndex + 1}/${batches.length} complete`);
        progress.increment();
        return scripts;
      } catch (err) {
        const message = err instanceof Error ? err.message : String(err);
        error(`Batch ${batchIndex + 1} failed: ${message}`);
        for (const test of batch) {
          console.log(`   ‚Ä¢ ${test.name}`);
        }
        progress.increment();
        return [];
      }
    }),
  );

  const results = await Promise.all(tasks);
  progress.succeed(`Built ${batches.length} batches`);

  return results.flat();
}

/**
 * Build E2E test scripts from scenarios
 */
async function buildE2EScripts(
  scenarios: E2EScenario[],
  client: LLMClient,
  loader: PromptLoader,
  options: BuildOptions,
  onScript: ScriptCallback,
): Promise<Array<{ name: string; code: string }>> {
  const prompts = await loader.loadBuilderPrompts(false, true);
  const limit = pLimit(options.workers);

  step('üîó', `Building ${scenarios.length} E2E test scripts`);

  const progress = new ProgressCounter(scenarios.length, 'Building E2E scripts');

  // Rate limiter
  const rpmDelay = options.rpm > 0 ? 60000 / options.rpm : 0;
  let lastRequestTime = 0;

  const tasks = scenarios.map(scenario =>
    limit(async () => {
      // Rate limiting
      if (rpmDelay > 0) {
        const now = Date.now();
        const timeSinceLastRequest = now - lastRequestTime;
        if (timeSinceLastRequest < rpmDelay) {
          await new Promise(resolve => setTimeout(resolve, rpmDelay - timeSinceLastRequest));
        }
        lastRequestTime = Date.now();
      }

      const stepsStr = scenario.steps.map(s => `- ${s}`).join('\n');
      const endpointSpec = JSON.stringify(scenario.endpoint_spec ?? {}, null, 2);

      const userPrompt = renderTemplate(prompts.user, {
        test_name: scenario.name,
        steps: stepsStr,
        description: scenario.description,
        endpoint_spec: endpointSpec,
      });

      try {
        const response = await client.generateWithRetry(prompts.system, userPrompt);
        const code = cleanCodeResponse(response);

        const { written } = await onScript(scenario.name, code);
        if (written) {
          success(`${scenario.name} (written)`);
        } else {
          step('‚è≠Ô∏è', `${scenario.name} (skipped)`);
        }

        progress.increment();
        return { name: scenario.name, code };
      } catch (err) {
        const message = err instanceof Error ? err.message : String(err);
        error(`${scenario.name} - ${message}`);
        progress.increment();
        return null;
      }
    }),
  );

  const results = await Promise.all(tasks);
  progress.succeed(`Built ${scenarios.length} E2E scripts`);

  return results.filter((r): r is { name: string; code: string } => r !== null);
}
