//! LLM-based test plan and script generation

use anyhow::{Context, Result};
use genai::adapter::AdapterKind;
use genai::chat::{ChatMessage, ChatRequest};
use genai::resolver::{AuthData, Endpoint, ServiceTargetResolver};
use genai::{Client, ClientBuilder, ModelIden, ServiceTarget};
use serde::{Deserialize, Serialize};
use std::fs;
use std::path::Path;

// Embed default prompts at compile time
const DEFAULT_PLANNER_SYSTEM: &str = include_str!("../prompts/planner_system.md");
const DEFAULT_PLANNER_USER: &str = include_str!("../prompts/planner_user.md");
const DEFAULT_BUILDER_SYSTEM: &str = include_str!("../prompts/builder_system.md");
const DEFAULT_BUILDER_USER: &str = include_str!("../prompts/builder_user.md");

/// A structured test scenario generated by the LLM
#[allow(dead_code)]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TestScenario {
    pub name: String,
    pub steps: Vec<String>,
    #[serde(default = "default_priority")]
    pub priority: String,
    #[serde(default)]
    pub tags: Vec<String>,
}

#[allow(dead_code)]
fn default_priority() -> String {
    "medium".to_string()
}

/// A single test entry in the test plan
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TestEntry {
    pub name: String,
    pub method: String,
    pub path: String,
    pub endpoint_spec: serde_json::Value,
}

/// The complete test plan that can be saved to JSON and loaded by the build phase
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TestPlan {
    /// Version of the test plan format
    pub version: String,
    /// Original OpenAPI spec path
    pub spec_path: String,
    /// API title from the spec
    pub api_title: String,
    /// API version from the spec
    pub api_version: String,
    /// List of test entries
    pub tests: Vec<TestEntry>,
}

impl TestPlan {
    pub fn new(spec_path: &str, api_title: &str, api_version: &str) -> Self {
        Self {
            version: "1.0".to_string(),
            spec_path: spec_path.to_string(),
            api_title: api_title.to_string(),
            api_version: api_version.to_string(),
            tests: Vec::new(),
        }
    }

    /// Save the test plan to a JSON file
    pub fn save(&self, path: &Path) -> Result<()> {
        let json = serde_json::to_string_pretty(self)?;
        fs::write(path, json)?;
        Ok(())
    }

    /// Load a test plan from a JSON file
    pub fn load(path: &Path) -> Result<Self> {
        let content = fs::read_to_string(path)
            .with_context(|| format!("Failed to read test plan from {:?}", path))?;
        let plan: TestPlan = serde_json::from_str(&content)
            .with_context(|| "Failed to parse test plan JSON")?;
        Ok(plan)
    }
}

/// Prompt loader that supports custom prompt directories
pub struct PromptLoader {
    prompt_dir: Option<String>,
}

impl PromptLoader {
    pub fn new(prompt_dir: Option<String>) -> Self {
        Self { prompt_dir }
    }

    /// Load a prompt, preferring custom file over embedded default
    fn load_prompt(&self, filename: &str, default: &str) -> String {
        if let Some(ref dir) = self.prompt_dir {
            let path = Path::new(dir).join(filename);
            if path.exists() {
                if let Ok(content) = fs::read_to_string(&path) {
                    return content;
                }
            }
        }
        default.to_string()
    }

    pub fn planner_system(&self) -> String {
        self.load_prompt("planner_system.md", DEFAULT_PLANNER_SYSTEM)
    }

    pub fn planner_user(&self) -> String {
        self.load_prompt("planner_user.md", DEFAULT_PLANNER_USER)
    }

    pub fn builder_system(&self) -> String {
        self.load_prompt("builder_system.md", DEFAULT_BUILDER_SYSTEM)
    }

    pub fn builder_user(&self) -> String {
        self.load_prompt("builder_user.md", DEFAULT_BUILDER_USER)
    }
}

/// Simple template replacement
fn render_template(template: &str, vars: &[(&str, &str)]) -> String {
    let mut result = template.to_string();
    for (key, value) in vars {
        result = result.replace(&format!("{{{{{}}}}}", key), value);
    }
    result
}

/// Detect the env var name from an API base URL
fn env_var_for_api_base(api_base: &str) -> &'static str {
    let base_lower = api_base.to_lowercase();
    if base_lower.contains("groq.com") {
        "GROQ_API_KEY"
    } else if base_lower.contains("together.xyz") || base_lower.contains("together.ai") {
        "TOGETHER_API_KEY"
    } else if base_lower.contains("fireworks.ai") {
        "FIREWORKS_API_KEY"
    } else if base_lower.contains("anthropic.com") {
        "ANTHROPIC_API_KEY"
    } else if base_lower.contains("x.ai") || base_lower.contains("xai.com") {
        "XAI_API_KEY"
    } else if base_lower.contains("deepseek.com") {
        "DEEPSEEK_API_KEY"
    } else if base_lower.contains("mistral.ai") {
        "MISTRAL_API_KEY"
    } else {
        // Default to OPENAI_API_KEY for OpenAI and unknown providers
        "OPENAI_API_KEY"
    }
}

/// Build a genai client.
/// - If api_base is Some, creates a custom resolver for that endpoint (OpenAI-compatible).
/// - If api_base is None, uses genai's default auto-detection from model name.
fn build_client(api_base: Option<&str>) -> Client {
    match api_base {
        Some(base) => {
            // Custom endpoint - detect env var from URL
            let env_var = env_var_for_api_base(base);
            let api_base = base.to_string();

            let target_resolver = ServiceTargetResolver::from_resolver_fn(
                move |service_target: ServiceTarget| -> Result<ServiceTarget, genai::resolver::Error> {
                    let endpoint = Endpoint::from_owned(api_base.clone());
                    let auth = AuthData::from_env(env_var);
                    // Force OpenAI adapter for custom endpoints (OpenAI-compatible API)
                    let model = ModelIden::new(AdapterKind::OpenAI, service_target.model.model_name);
                    Ok(ServiceTarget {
                        endpoint,
                        auth,
                        model,
                    })
                },
            );

            ClientBuilder::default()
                .with_service_target_resolver(target_resolver)
                .build()
        }
        None => {
            // Let genai auto-detect provider from model name
            // Auth is automatically loaded from provider-specific env vars:
            // GROQ_API_KEY, OPENAI_API_KEY, ANTHROPIC_API_KEY, etc.
            Client::default()
        }
    }
}

/// Represents a single API endpoint extracted from OpenAPI spec
#[derive(Debug, Clone)]
struct EndpointInfo {
    path: String,
    method: String,
    spec: serde_json::Value,
}

/// Extract individual endpoints from an OpenAPI spec
fn extract_endpoints(spec: &str) -> Result<Vec<EndpointInfo>> {
    let spec_json: serde_json::Value = serde_json::from_str(spec)
        .with_context(|| "Failed to parse OpenAPI spec as JSON")?;

    let paths = spec_json
        .get("paths")
        .and_then(|p| p.as_object())
        .with_context(|| "OpenAPI spec missing 'paths' object")?;

    let mut endpoints = Vec::new();

    for (path, path_item) in paths {
        if let Some(path_obj) = path_item.as_object() {
            for (method, operation) in path_obj {
                // Skip non-HTTP method keys like "parameters", "summary", etc.
                let http_methods = ["get", "post", "put", "patch", "delete", "head", "options"];
                if !http_methods.contains(&method.to_lowercase().as_str()) {
                    continue;
                }

                // Build a minimal spec for this endpoint
                let endpoint_spec = serde_json::json!({
                    "path": path,
                    "method": method.to_uppercase(),
                    "operation": operation
                });

                endpoints.push(EndpointInfo {
                    path: path.clone(),
                    method: method.to_uppercase(),
                    spec: endpoint_spec,
                });
            }
        }
    }

    Ok(endpoints)
}

/// Parse LLM response to extract test names
fn parse_test_names(content: &str) -> Result<Vec<String>> {
    // Clean up any markdown fences that might be present
    let clean_json = content
        .trim()
        .trim_start_matches("```json")
        .trim_start_matches("```")
        .trim_end_matches("```")
        .trim();

    // Parse as array of strings
    let names: Vec<String> = serde_json::from_str(clean_json)
        .with_context(|| format!("Failed to parse LLM response as JSON array: {}", content))?;

    Ok(names)
}

/// Result of planning for a single endpoint (for TestPlan generation)
struct PlanResult {
    method: String,
    path: String,
    endpoint_spec: serde_json::Value,
    test_names: Result<Vec<String>>,
}

/// Create a TestPlan from an OpenAPI spec using an LLM
/// This generates a JSON-serializable plan that can be saved and used by the build phase
///
/// # Arguments
/// * `spec` - The OpenAPI specification as a JSON string
/// * `spec_path` - Path to the original spec file (for reference)
/// * `api_base` - Optional custom API base URL
/// * `model_name` - The LLM model to use
/// * `prompt_dir` - Optional custom prompt directory
/// * `workers` - Number of parallel workers (0 = unlimited)
/// * `rpm` - Maximum requests per minute (0 = unlimited)
pub fn create_test_plan(
    spec: &str,
    spec_path: &str,
    api_base: Option<&str>,
    model_name: &str,
    prompt_dir: Option<String>,
    workers: usize,
    rpm: u32,
) -> Result<TestPlan> {
    let client = build_client(api_base);
    let loader = PromptLoader::new(prompt_dir.clone());
    let system_prompt = loader.planner_system();
    let user_template = loader.planner_user();

    // Parse spec to get API info
    let spec_json: serde_json::Value = serde_json::from_str(spec)
        .with_context(|| "Failed to parse OpenAPI spec as JSON")?;
    
    let api_title = spec_json
        .get("info")
        .and_then(|i| i.get("title"))
        .and_then(|t| t.as_str())
        .unwrap_or("Unknown API")
        .to_string();
    
    let api_version = spec_json
        .get("info")
        .and_then(|i| i.get("version"))
        .and_then(|v| v.as_str())
        .unwrap_or("0.0.0")
        .to_string();

    // Extract all endpoints from the spec
    let endpoints = extract_endpoints(spec)?;
    let endpoint_count = endpoints.len();

    // Determine effective worker count
    let effective_workers = if workers == 0 { endpoint_count } else { workers.min(endpoint_count) };

    println!("üìã Found {} endpoints to process", endpoint_count);
    println!("üë∑ Using {} parallel workers", effective_workers);
    if rpm > 0 {
        println!("‚è±Ô∏è  Rate limit: {} requests/minute", rpm);
    }
    println!();

    // Print what we're about to process
    for endpoint in &endpoints {
        println!("   ‚Ä¢ {} {}", endpoint.method, endpoint.path);
    }
    println!();

    let rt = tokio::runtime::Runtime::new()?;

    // Process endpoints in parallel with worker limit and rate limiting
    let (test_entries, success_count, fail_count) = rt.block_on(async {
        use std::sync::Arc;
        use tokio::sync::{mpsc, Mutex, Semaphore};
        use tokio::time::{Duration, Instant};

        let semaphore = Arc::new(Semaphore::new(effective_workers));
        
        // Rate limiter state: tracks the last request time
        let rate_limiter = if rpm > 0 {
            let interval_ms = 60_000 / rpm as u64;
            Some(Arc::new(Mutex::new((Instant::now(), interval_ms))))
        } else {
            None
        };

        // Channel to receive results as they complete
        let (tx, mut rx) = mpsc::unbounded_channel::<PlanResult>();
        
        let mut handles = Vec::new();

        for endpoint in endpoints {
            let client = client.clone();
            let model = model_name.to_string();
            let system = system_prompt.clone();
            let template = user_template.clone();
            let ep_method = endpoint.method.clone();
            let ep_path = endpoint.path.clone();
            let ep_spec = endpoint.spec.clone();
            let sem = Arc::clone(&semaphore);
            let rl = rate_limiter.clone();
            let tx = tx.clone();

            let handle = tokio::spawn(async move {
                let _permit = sem.acquire().await.unwrap();

                // Apply rate limiting if configured
                if let Some(ref limiter) = rl {
                    let mut state = limiter.lock().await;
                    let (last_time, interval_ms) = *state;
                    let elapsed = last_time.elapsed().as_millis() as u64;
                    if elapsed < interval_ms {
                        tokio::time::sleep(Duration::from_millis(interval_ms - elapsed)).await;
                    }
                    *state = (Instant::now(), interval_ms);
                }

                let endpoint_spec_str = serde_json::to_string_pretty(&ep_spec)
                    .unwrap_or_else(|_| "{}".to_string());
                let user_prompt = render_template(&template, &[("spec", &endpoint_spec_str)]);

                let chat_req = ChatRequest::new(vec![
                    ChatMessage::system(&system),
                    ChatMessage::user(user_prompt),
                ]);

                let result = client.exec_chat(&model, chat_req, None).await;

                let test_names = match result {
                    Ok(response) => {
                        let content = response.first_text().unwrap_or_default();
                        parse_test_names(&content)
                    }
                    Err(e) => Err(anyhow::anyhow!("LLM call failed: {}", e)),
                };

                // Send result through channel (ignore error if receiver dropped)
                let _ = tx.send(PlanResult {
                    method: ep_method,
                    path: ep_path,
                    endpoint_spec: ep_spec,
                    test_names,
                });
            });

            handles.push(handle);
        }

        // Drop the original sender so the channel closes when all tasks complete
        drop(tx);

        // Collect results as they arrive and print immediately
        let mut test_entries = Vec::new();
        let mut success_count = 0;
        let mut fail_count = 0;

        while let Some(result) = rx.recv().await {
            match result.test_names {
                Ok(names) => {
                    println!(
                        "‚úÖ {} {} - {} tests",
                        result.method,
                        result.path,
                        names.len()
                    );
                    success_count += 1;
                    for name in names {
                        test_entries.push(TestEntry {
                            name,
                            method: result.method.clone(),
                            path: result.path.clone(),
                            endpoint_spec: result.endpoint_spec.clone(),
                        });
                    }
                }
                Err(e) => {
                    println!("‚ùå {} {} - Error: {}", result.method, result.path, e);
                    fail_count += 1;
                }
            }
        }

        // Wait for all tasks to complete (they should already be done)
        for handle in handles {
            let _ = handle.await;
        }

        (test_entries, success_count, fail_count)
    });

    // Build the test plan
    let mut plan = TestPlan::new(spec_path, &api_title, &api_version);
    plan.tests = test_entries;

    println!(
        "\nüìä Summary: {} endpoints succeeded, {} failed",
        success_count, fail_count
    );
    println!("‚úÖ Total: {} test entries in plan", plan.tests.len());

    Ok(plan)
}

/// Result of generating a single test script
struct ScriptResult {
    test_name: String,
    code: Result<String>,
}

/// Build test scripts from a TestPlan
/// 
/// # Arguments
/// * `plan` - The test plan to generate scripts from
/// * `api_base` - Optional custom API base URL
/// * `model_name` - The LLM model to use
/// * `prompt_dir` - Optional custom prompt directory
/// * `workers` - Number of parallel workers (0 = unlimited)
/// * `rpm` - Maximum requests per minute (0 = unlimited)
pub fn build_scripts_from_plan(
    plan: &TestPlan,
    api_base: Option<&str>,
    model_name: &str,
    prompt_dir: Option<String>,
    workers: usize,
    rpm: u32,
) -> Result<Vec<(String, String)>> {
    let client = build_client(api_base);
    let loader = PromptLoader::new(prompt_dir);
    let system_prompt = loader.builder_system();
    let user_template = loader.builder_user();

    let test_count = plan.tests.len();
    let effective_workers = if workers == 0 {
        test_count
    } else {
        workers.min(test_count)
    };

    println!("\nüèóÔ∏è  Building {} test scripts", test_count);
    println!("üë∑ Using {} parallel workers", effective_workers);
    if rpm > 0 {
        println!("‚è±Ô∏è  Rate limit: {} requests/minute", rpm);
    }
    println!();

    let rt = tokio::runtime::Runtime::new()?;

    let (scripts, success_count, fail_count) = rt.block_on(async {
        use std::sync::Arc;
        use tokio::sync::{mpsc, Mutex, Semaphore};
        use tokio::time::{Duration, Instant};

        let semaphore = Arc::new(Semaphore::new(effective_workers));
        
        // Rate limiter state: tracks the last request time
        let rate_limiter = if rpm > 0 {
            let interval_ms = 60_000 / rpm as u64;
            Some(Arc::new(Mutex::new((Instant::now(), interval_ms))))
        } else {
            None
        };

        // Channel to receive results as they complete
        let (tx, mut rx) = mpsc::unbounded_channel::<ScriptResult>();
        
        let mut handles = Vec::new();

        for test in &plan.tests {
            let client = client.clone();
            let model = model_name.to_string();
            let system = system_prompt.clone();
            let template = user_template.clone();
            let test_name = test.name.clone();
            let endpoint_spec = test.endpoint_spec.clone();
            let sem = Arc::clone(&semaphore);
            let rl = rate_limiter.clone();
            let tx = tx.clone();

            let handle = tokio::spawn(async move {
                let _permit = sem.acquire().await.unwrap();

                // Apply rate limiting if configured
                if let Some(ref limiter) = rl {
                    let mut state = limiter.lock().await;
                    let (last_time, interval_ms) = *state;
                    let elapsed = last_time.elapsed().as_millis() as u64;
                    if elapsed < interval_ms {
                        tokio::time::sleep(Duration::from_millis(interval_ms - elapsed)).await;
                    }
                    *state = (Instant::now(), interval_ms);
                }

                let endpoint_spec_str = serde_json::to_string_pretty(&endpoint_spec)
                    .unwrap_or_else(|_| "{}".to_string());

                let user_prompt = render_template(
                    &template,
                    &[
                        ("test_name", &test_name),
                        ("endpoint_spec", &endpoint_spec_str),
                    ],
                );

                let chat_req = ChatRequest::new(vec![
                    ChatMessage::system(&system),
                    ChatMessage::user(user_prompt),
                ]);

                let result = client.exec_chat(&model, chat_req, None).await;

                let code = match result {
                    Ok(response) => {
                        let raw_code = response.first_text().unwrap_or_default();
                        let clean_code = raw_code
                            .trim()
                            .trim_start_matches("```javascript")
                            .trim_start_matches("```js")
                            .trim_start_matches("```")
                            .trim_end_matches("```")
                            .trim()
                            .to_string();
                        Ok(clean_code)
                    }
                    Err(e) => Err(anyhow::anyhow!("LLM call failed: {}", e)),
                };

                // Send result through channel (ignore error if receiver dropped)
                let _ = tx.send(ScriptResult { test_name, code });
            });

            handles.push(handle);
        }

        // Drop the original sender so the channel closes when all tasks complete
        drop(tx);

        // Collect results as they arrive and print immediately
        let mut scripts = Vec::new();
        let mut success_count = 0;
        let mut fail_count = 0;

        while let Some(result) = rx.recv().await {
            match result.code {
                Ok(code) => {
                    println!("‚úÖ {}", result.test_name);
                    success_count += 1;
                    scripts.push((result.test_name, code));
                }
                Err(e) => {
                    println!("‚ùå {} - Error: {}", result.test_name, e);
                    fail_count += 1;
                }
            }
        }

        // Wait for all tasks to complete (they should already be done)
        for handle in handles {
            let _ = handle.await;
        }

        (scripts, success_count, fail_count)
    });

    println!(
        "\nüìä Scripts: {} generated, {} failed",
        success_count, fail_count
    );

    Ok(scripts)
}

/// Parse LLM response content to extract clean JSON
#[allow(dead_code)]
pub fn parse_llm_json_response(content: &str) -> String {
    content
        .trim()
        .trim_start_matches("```json")
        .trim_start_matches("```")
        .trim_end_matches("```")
        .trim()
        .to_string()
}

/// Parse LLM response content to extract clean code
#[allow(dead_code)]
pub fn parse_llm_code_response(content: &str) -> String {
    content
        .trim()
        .trim_start_matches("```javascript")
        .trim_start_matches("```js")
        .trim_start_matches("```")
        .trim_end_matches("```")
        .trim()
        .to_string()
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use tempfile::tempdir;

    // ============================================
    // TestScenario JSON Parsing Tests
    // ============================================

    #[test]
    fn test_parse_test_scenario_minimal() {
        let json = r#"{
            "name": "Test Login",
            "steps": ["Step 1", "Step 2"]
        }"#;
        let scenario: TestScenario = serde_json::from_str(json).unwrap();
        assert_eq!(scenario.name, "Test Login");
        assert_eq!(scenario.steps.len(), 2);
        assert_eq!(scenario.priority, "medium"); // default
        assert!(scenario.tags.is_empty()); // default
    }

    #[test]
    fn test_parse_test_scenario_full() {
        let json = r#"{
            "name": "Test User Registration",
            "steps": ["Create user", "Verify email", "Login"],
            "priority": "high",
            "tags": ["auth", "user", "critical"]
        }"#;
        let scenario: TestScenario = serde_json::from_str(json).unwrap();
        assert_eq!(scenario.name, "Test User Registration");
        assert_eq!(scenario.steps.len(), 3);
        assert_eq!(scenario.priority, "high");
        assert_eq!(scenario.tags, vec!["auth", "user", "critical"]);
    }

    #[test]
    fn test_parse_test_scenario_array() {
        let json = r#"[
            {"name": "Test 1", "steps": ["step 1"]},
            {"name": "Test 2", "steps": ["step 2"], "priority": "low"},
            {"name": "Test 3", "steps": ["step 3"], "tags": ["smoke"]}
        ]"#;
        let scenarios: Vec<TestScenario> = serde_json::from_str(json).unwrap();
        assert_eq!(scenarios.len(), 3);
        assert_eq!(scenarios[0].name, "Test 1");
        assert_eq!(scenarios[1].priority, "low");
        assert_eq!(scenarios[2].tags, vec!["smoke"]);
    }

    #[test]
    fn test_parse_test_scenario_empty_steps() {
        let json = r#"{"name": "Empty Test", "steps": []}"#;
        let scenario: TestScenario = serde_json::from_str(json).unwrap();
        assert!(scenario.steps.is_empty());
    }

    #[test]
    fn test_parse_test_scenario_serialization() {
        let scenario = TestScenario {
            name: "Test Serialization".to_string(),
            steps: vec!["Step 1".to_string(), "Step 2".to_string()],
            priority: "high".to_string(),
            tags: vec!["tag1".to_string()],
        };
        let json = serde_json::to_string(&scenario).unwrap();
        assert!(json.contains("\"name\":\"Test Serialization\""));
        assert!(json.contains("\"priority\":\"high\""));
    }

    #[test]
    fn test_test_scenario_clone() {
        let scenario = TestScenario {
            name: "Original".to_string(),
            steps: vec!["Step".to_string()],
            priority: "high".to_string(),
            tags: vec!["tag".to_string()],
        };
        let cloned = scenario.clone();
        assert_eq!(cloned.name, scenario.name);
        assert_eq!(cloned.steps, scenario.steps);
    }

    // ============================================
    // Template Rendering Tests
    // ============================================

    #[test]
    fn test_render_template_single_var() {
        let template = "Hello, {{name}}!";
        let result = render_template(template, &[("name", "World")]);
        assert_eq!(result, "Hello, World!");
    }

    #[test]
    fn test_render_template_multiple_vars() {
        let template = "{{greeting}}, {{name}}! Your score is {{score}}.";
        let result = render_template(
            template,
            &[("greeting", "Hello"), ("name", "Alice"), ("score", "100")],
        );
        assert_eq!(result, "Hello, Alice! Your score is 100.");
    }

    #[test]
    fn test_render_template_no_vars() {
        let template = "No variables here.";
        let result = render_template(template, &[]);
        assert_eq!(result, "No variables here.");
    }

    #[test]
    fn test_render_template_missing_var() {
        let template = "Hello, {{name}}!";
        let result = render_template(template, &[]); // No replacement provided
        assert_eq!(result, "Hello, {{name}}!"); // Should remain unchanged
    }

    #[test]
    fn test_render_template_duplicate_var() {
        let template = "{{name}} met {{name}} at the {{name}} store.";
        let result = render_template(template, &[("name", "Bob")]);
        assert_eq!(result, "Bob met Bob at the Bob store.");
    }

    #[test]
    fn test_render_template_empty_value() {
        let template = "Value: {{value}}";
        let result = render_template(template, &[("value", "")]);
        assert_eq!(result, "Value: ");
    }

    #[test]
    fn test_render_template_multiline() {
        let template = "Line 1: {{var1}}\nLine 2: {{var2}}\nLine 3: {{var3}}";
        let result = render_template(
            template,
            &[("var1", "A"), ("var2", "B"), ("var3", "C")],
        );
        assert_eq!(result, "Line 1: A\nLine 2: B\nLine 3: C");
    }

    #[test]
    fn test_render_template_json_content() {
        let template = "Spec: {{spec}}";
        let json_content = r#"{"openapi": "3.0.0", "info": {"title": "API"}}"#;
        let result = render_template(template, &[("spec", json_content)]);
        assert!(result.contains("openapi"));
    }

    #[test]
    fn test_render_template_special_chars_in_value() {
        let template = "Data: {{data}}";
        let result = render_template(template, &[("data", "<html>&amp;\"quotes\"</html>")]);
        assert_eq!(result, "Data: <html>&amp;\"quotes\"</html>");
    }

    // ============================================
    // LLM Response Parsing Tests
    // ============================================

    #[test]
    fn test_parse_llm_json_response_clean() {
        let content = r#"[{"name": "test", "steps": ["step1"]}]"#;
        let result = parse_llm_json_response(content);
        assert_eq!(result, r#"[{"name": "test", "steps": ["step1"]}]"#);
    }

    #[test]
    fn test_parse_llm_json_response_with_markdown() {
        let content = "```json\n[{\"name\": \"test\"}]\n```";
        let result = parse_llm_json_response(content);
        assert_eq!(result, r#"[{"name": "test"}]"#);
    }

    #[test]
    fn test_parse_llm_json_response_with_plain_markdown() {
        let content = "```\n{\"key\": \"value\"}\n```";
        let result = parse_llm_json_response(content);
        assert_eq!(result, r#"{"key": "value"}"#);
    }

    #[test]
    fn test_parse_llm_json_response_with_whitespace() {
        let content = "   \n  ```json\n{\"test\": true}\n```  \n  ";
        let result = parse_llm_json_response(content);
        assert_eq!(result, r#"{"test": true}"#);
    }

    #[test]
    fn test_parse_llm_code_response_javascript() {
        let content = "```javascript\nconst x = 1;\nconsole.log(x);\n```";
        let result = parse_llm_code_response(content);
        assert_eq!(result, "const x = 1;\nconsole.log(x);");
    }

    #[test]
    fn test_parse_llm_code_response_js() {
        let content = "```js\nfunction test() { return true; }\n```";
        let result = parse_llm_code_response(content);
        assert_eq!(result, "function test() { return true; }");
    }

    #[test]
    fn test_parse_llm_code_response_plain() {
        let content = "```\nlet result = http.get('/api');\n```";
        let result = parse_llm_code_response(content);
        assert_eq!(result, "let result = http.get('/api');");
    }

    #[test]
    fn test_parse_llm_code_response_no_markers() {
        let content = "const response = http.get('/health');";
        let result = parse_llm_code_response(content);
        assert_eq!(result, "const response = http.get('/health');");
    }

    // ============================================
    // PromptLoader Tests
    // ============================================

    #[test]
    fn test_prompt_loader_default_prompts() {
        let loader = PromptLoader::new(None);

        // Should return embedded defaults
        let planner_system = loader.planner_system();
        let planner_user = loader.planner_user();
        let builder_system = loader.builder_system();
        let builder_user = loader.builder_user();

        // Verify defaults are non-empty
        assert!(!planner_system.is_empty());
        assert!(!planner_user.is_empty());
        assert!(!builder_system.is_empty());
        assert!(!builder_user.is_empty());
    }

    #[test]
    fn test_prompt_loader_custom_directory() {
        let dir = tempdir().unwrap();
        let custom_prompt = "Custom system prompt content";

        // Create custom prompt file
        let prompt_path = dir.path().join("planner_system.md");
        fs::write(&prompt_path, custom_prompt).unwrap();

        let loader = PromptLoader::new(Some(dir.path().to_string_lossy().to_string()));
        let result = loader.planner_system();

        assert_eq!(result, custom_prompt);
    }

    #[test]
    fn test_prompt_loader_fallback_to_default() {
        let dir = tempdir().unwrap();
        // Don't create any files - should fall back to defaults

        let loader = PromptLoader::new(Some(dir.path().to_string_lossy().to_string()));
        let result = loader.planner_system();

        // Should return embedded default
        assert!(!result.is_empty());
    }

    #[test]
    fn test_prompt_loader_partial_custom() {
        let dir = tempdir().unwrap();

        // Only create one custom prompt
        let custom_content = "My custom builder system prompt";
        fs::write(dir.path().join("builder_system.md"), custom_content).unwrap();

        let loader = PromptLoader::new(Some(dir.path().to_string_lossy().to_string()));

        // This should use custom
        assert_eq!(loader.builder_system(), custom_content);

        // These should use defaults
        assert!(!loader.planner_system().is_empty());
        assert!(!loader.planner_user().is_empty());
        assert!(!loader.builder_user().is_empty());
    }

    #[test]
    fn test_prompt_loader_nonexistent_directory() {
        let loader = PromptLoader::new(Some("/nonexistent/path/to/prompts".to_string()));

        // Should fall back to defaults
        assert!(!loader.planner_system().is_empty());
    }

    // ============================================
    // Default Priority Tests
    // ============================================

    #[test]
    fn test_default_priority() {
        assert_eq!(default_priority(), "medium");
    }

    // ============================================
    // Complex JSON Parsing Tests
    // ============================================

    #[test]
    fn test_parse_complex_scenarios() {
        let json = r#"[
            {
                "name": "API Health Check",
                "steps": [
                    "Send GET request to /health",
                    "Verify response status is 200",
                    "Check response body contains 'ok'"
                ],
                "priority": "critical",
                "tags": ["health", "smoke", "monitoring"]
            },
            {
                "name": "User CRUD Operations",
                "steps": [
                    "Create a new user with POST /users",
                    "Read user with GET /users/{id}",
                    "Update user with PUT /users/{id}",
                    "Delete user with DELETE /users/{id}",
                    "Verify user no longer exists"
                ],
                "priority": "high",
                "tags": ["crud", "user-management"]
            }
        ]"#;

        let scenarios: Vec<TestScenario> = serde_json::from_str(json).unwrap();
        assert_eq!(scenarios.len(), 2);
        assert_eq!(scenarios[0].steps.len(), 3);
        assert_eq!(scenarios[1].steps.len(), 5);
        assert_eq!(scenarios[0].tags.len(), 3);
    }

    #[test]
    fn test_parse_scenario_with_unicode() {
        let json = r#"{
            "name": "ÂõΩÈôÖÂåñÊµãËØï - Internationalization Test",
            "steps": ["Ê≠•È™§‰∏Ä - Step 1", "√âtape 2", "Schritt 3 üöÄ"],
            "priority": "medium",
            "tags": ["i18n", "unicode", "Â§öËØ≠Ë®Ä"]
        }"#;

        let scenario: TestScenario = serde_json::from_str(json).unwrap();
        assert!(scenario.name.contains("ÂõΩÈôÖÂåñ"));
        assert!(scenario.steps[2].contains("üöÄ"));
        assert!(scenario.tags.contains(&"Â§öËØ≠Ë®Ä".to_string()));
    }

    #[test]
    fn test_parse_scenario_with_special_chars_in_steps() {
        let json = r#"{
            "name": "Test Special Characters",
            "steps": [
                "Send request with query param ?foo=bar&baz=qux",
                "Verify response contains \"escaped quotes\"",
                "Check header X-Custom: value/with/slashes"
            ]
        }"#;

        let scenario: TestScenario = serde_json::from_str(json).unwrap();
        assert!(scenario.steps[0].contains("&"));
        assert!(scenario.steps[1].contains("\""));
        assert!(scenario.steps[2].contains("/"));
    }
}

